{
  "hash": "4143836733ad4f967f673606a1b43535",
  "result": {
    "markdown": "# Weighting {#sec-ex-weighting}\n\n\n\n\n\nNext, we'll use weighting to target the ATE of RHC on death[^ex-weight-1]. We'll use the `WeightIt` package, which provides an interface to many different weighting methods and has utilities for assessing the quality of the weights. For more details on this procedure, including effect estimation, see the `WeightIt` [documentation](https://ngreifer.github.io/WeightIt/) and vignettes.\n\n[^ex-weight-1]: Note that the ATE can be targeted by matching (not 1:1 matching, but other methods) and the ATT and other estimands can be targeted by weighting; don't think matching is for the ATT and weighting is for the ATE. Use whichever method yields the best performance and would be best understood by your audience.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"WeightIt\")\n```\n:::\n\n\nFirst we'll perform the most common weighting method, inverse probability weighting using a logistic regression propensity score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nw1 <- weightit(RHC ~ aps1 + meanbp1 + pafi1 + crea1 + hema1 +\n                paco21 + surv2md1 + resp1 + card + edu +\n                age + race + sex, data = rhc,\n               estimand = \"ATE\")\nw1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA weightit object\n - method: \"glm\" (propensity score weighting with GLM)\n - number of obs.: 5735\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATE\n - covariates: aps1, meanbp1, pafi1, crea1, hema1, paco21, surv2md1, resp1, card, edu, age, race, sex\n```\n:::\n:::\n\n\nWe'll use `bal.tab()` again to assess balance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbal.tab(w1, stats = c(\"m\", \"ks\"), binary = \"std\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBalance Measures\n               Type Diff.Adj KS.Adj\nprop.score Distance  -0.0243 0.0281\naps1        Contin.  -0.0256 0.0222\nmeanbp1     Contin.   0.0168 0.0331\npafi1       Contin.   0.0020 0.0253\ncrea1       Contin.  -0.0119 0.0646\nhema1       Contin.  -0.0265 0.0575\npaco21      Contin.   0.0024 0.0218\nsurv2md1    Contin.   0.0141 0.0344\nresp1       Contin.   0.0339 0.0475\ncard_Yes     Binary  -0.0065 0.0031\nedu         Contin.   0.0105 0.0206\nage         Contin.   0.0109 0.0565\nrace_white   Binary   0.0058 0.0024\nrace_black   Binary  -0.0031 0.0011\nrace_other   Binary  -0.0053 0.0013\nsex_Male     Binary  -0.0021 0.0011\n\nEffective sample sizes\n           Control Treated\nUnadjusted 3551.   2184.  \nAdjusted   2657.85 1509.52\n```\n:::\n:::\n\n\nBalance looks excellent using standard inverse probability weighting, and normally we might stop here. However, we'll carry on in search of even better balance. We'll use entropy balancing, which guarantees exact balance on the means of included covariates (but may not balance the rest of the covariate distributions).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nw2 <- weightit(RHC ~ aps1 + meanbp1 + pafi1 + crea1 + hema1 +\n                paco21 + surv2md1 + resp1 + card + edu +\n                age + race + sex, data = rhc,\n               estimand = \"ATE\", method = \"entropy\")\nw2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA weightit object\n - method: \"ebal\" (entropy balancing)\n - number of obs.: 5735\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATE\n - covariates: aps1, meanbp1, pafi1, crea1, hema1, paco21, surv2md1, resp1, card, edu, age, race, sex\n```\n:::\n\n```{.r .cell-code}\nbal.tab(w2, binary = \"std\", int = TRUE,\n        poly = 4, thresholds = c(m = .05),\n        disp.bal.tab = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBalance tally for mean differences\n                    count\nBalanced, <0.05       164\nNot Balanced, >0.05    12\n\nVariable with the greatest mean difference\n Variable Diff.Adj         M.Threshold\n   crea1³  -0.1005 Not Balanced, >0.05\n\nEffective sample sizes\n           Control Treated\nUnadjusted 3551.   2184.  \nAdjusted   3160.98 1542.59\n```\n:::\n:::\n\n\nHere we included interactions and up to fourth powers of the covariates to assess balance more fully on the covariate distributions; although balance after entropy balancing was excellent, it might still be possible to improve on it. We could request that entropy balancing additionally balances specific powers of the covariates using the `moments` and `int` arguments. Instead, we'll try energy balancing, which tends to have excellent performance at balancing the entire covariate distribution and doesn't require manually specifying components to balance (but it can be a bit slow on larger datasets).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nw3 <- weightit(RHC ~ aps1 + meanbp1 + pafi1 + crea1 + hema1 +\n                paco21 + surv2md1 + resp1 + card + edu +\n                age + race + sex, data = rhc,\n               estimand = \"ATE\", method = \"energy\")\nw3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA weightit object\n - method: \"energy\" (energy balancing)\n - number of obs.: 5735\n - sampling weights: none\n - treatment: 2-category\n - estimand: ATE\n - covariates: aps1, meanbp1, pafi1, crea1, hema1, paco21, surv2md1, resp1, card, edu, age, race, sex\n```\n:::\n\n```{.r .cell-code}\nbal.tab(w3, binary = \"std\", int = TRUE,\n        poly = 4, thresholds = c(m = .05),\n        disp.bal.tab = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBalance tally for mean differences\n                    count\nBalanced, <0.05       176\nNot Balanced, >0.05     0\n\nVariable with the greatest mean difference\n Variable Diff.Adj     M.Threshold\n     age⁴  -0.0211 Balanced, <0.05\n\nEffective sample sizes\n           Control Treated\nUnadjusted 3551.   2184.  \nAdjusted   2524.81 1212.94\n```\n:::\n:::\n\n\nWe find that energy balancing was successful at balancing the full covariate distribution. We'll carry on with our energy balancing results.\n\nTo estimate the treatment effect, we will again use g-computation, aided by the `marginaleffects` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"marginaleffects\")\n```\n:::\n\n\nFirst, we need to extract the weights from our `weightit` object, and then we fit the outcome model. Remember, this model is not to be interpreted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bring the weights into the dataset\nrhc$weights <- w3$weights\n\n# Fit the outcome model\nfit <- glm(death ~ RHC * (aps1 + meanbp1 + pafi1 + crea1 + hema1 +\n                            paco21 + surv2md1 + resp1 + card + edu +\n                            age + race + sex),\n           data = rhc, weights = weights, family = quasibinomial)\n```\n:::\n\n\nNext we'll compute the marginal predictions and their ratio. Here we'll request robust standard errors, which are generally appropriate for weighting for the ATE (though they may be conservative).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Marginal predictions\navg_predictions(fit, variables = \"RHC\",\n                wts = \"weights\",\n                vcov = \"HC3\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n RHC Estimate Pr(>|z|) 2.5 % 97.5 %\n   0    0.668   <0.001 0.646  0.689\n   1    0.699   <0.001 0.669  0.728\n\nColumns: RHC, estimate, p.value, conf.low, conf.high \n```\n:::\n\n```{.r .cell-code}\n# Risk ratio\navg_comparisons(fit, variables = \"RHC\",\n                wts = \"weights\",\n                vcov = \"HC3\",\n                comparison = \"lnratioavg\",\n                transform = \"exp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Term              Contrast Estimate Pr(>|z|) 2.5 % 97.5 %\n  RHC ln(mean(1) / mean(0))     1.05   0.0325     1    1.1\n\nColumns: term, contrast, estimate, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo \n```\n:::\n:::\n\n\nHere we find evidence of a positive risk ratio overall, indicating that on average, receiving RHC increases the risk of death by 5%[^ex-weight-2].\n\n[^ex-weight-2]: Note, in this case, the conclusions would have been the same regardless of which weighting method we moved forward with.\n\nAgain, it is useful to report balance to demonstrate the performance of the weights. Here, we could say that the largest SMD for the covariates was .004 and the largest KS statistic was .029, and the SMDs for all powers of the covariates up to 4 and two-way interactions were less than .021. The specific values for each covariate would not be required because this summary indicates that all covariates were balanced more than adequately.\n",
    "supporting": [
      "ex-weight_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}